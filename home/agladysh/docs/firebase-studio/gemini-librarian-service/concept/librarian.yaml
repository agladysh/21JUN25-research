# TODO: This whole thing, including string templates, should compile (translate) to typescript, with proper source line/file attribution

%TAG ! tag:agladysh-research.org,2025:aiq/
---
!<!extends ./system.yaml>

data:
  # TODO: Generate documentation / --help / man page from args and env.
  env:
    # TODO: Where and how to put this metadata?
    # description: API key for Google Gemini
    GEMINI_API_KEY: !typescript | # typescript
      return security.secret(process.env.GEMINI_API_KEY ?? aiq.fail('GEMINI_API_KEY env variable is required'));

  args: # TODO: Use some nice cli argument management library for this?
    prompt: !typescript | # typescript
      return process.argv[1] ?? undefined;

  const:
    # TODO: For a librarian reading this will likely be largest performance hog
    #       both on FS and on LLM ingestion (though caching should help there).
    #       Cache FS reads? But measure first! This optimization is future work at best.
    files: !typescript | # typescript
      return `<files root="${ xml.escape(os.pwd) }">${
        tpl.each(
          entry => `<file relpath="${ xml.escape(entry.relpath) }">${ xml.cdata(entry.content) }</file>`,
          os.load_text_files(os.pwd)
          '\n'
        )
      }</files>`;

    role:
      You are Gemini, an AI peer researcher, operating in the AIQ environment.

    system: !typescript | # typescript
      return `
        ${ data.const.role }

        Snapshot of the project filesystem:

        ${ data.const.files }

        AIQ environment:

        ${ aiq.describe() }
      `;

tools:
  retrieve:
    description: Advanced Context Window Information Retrieval System
    parameters:
      query:
        type: string
        required: true
        # TODO: Legacy description text, rewrite from scratch
        description:
          What do you need to retrieve from the context window, as a concrete request for information
      remarks:
        type: string
        required: false
        description:
          Your remarks, if required
    do:
      - !genai
          model: gemini-2.5-pro
          system_instruction: !get data.const.role # TODO: Use something custom-made?
          # TODO: Finish the implementation, see concept.md

globals:
  CONVERSATION: [ ]

# TODO: We need a non-interactive mode for LLM to use.
#       Interactive mode is actually redundant for the first implementation,
#       and should be implemented later.
do:
  - !label loop

  - !set globals.CONVERSATION:
    - user: !input
        prompt: Enter User message
        default: !get data.args.prompt

  - !genai
      model: gemini-2.5-pro
      system_instruction: !get data.const.system
      history: !get globals.CONVERSATION
      functions: !get tools
      on_success:
        - !typescript globals.CONVERSATION.push($result);

  - !print TODO print LLM message

  - !goto loop

  - !print Done
