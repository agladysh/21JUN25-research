Subject: Introducing a Human–AI Collaborative Research Project Dear Colleagues, I’m excited to share an ambitious new research initiative that pairs a human researcher (myself) with multiple AI agents as equal collaborators
GitHub
. In this project, cutting-edge Large Language Models (LLMs) and other AI systems work as “full peers” alongside me – not just as tools or assistants, but as intelligent partners contributing ideas, writing code, and solving problems. Our ultimate goal is to accelerate and “battle-test” my ideas in the public arena by harnessing this human–AI team of peers
GitHub
. We’re essentially creating a “collective mind” workspace where human and AI minds blend their strengths to tackle complex challenges
GitHub
. Project Structure & Key Components: At the heart of this collaboration is a carefully structured repository and documentation system that facilitates seamless interaction between all participants, human and AI. We’ve established an AGENTS.md guide in the repo that explicitly defines the AI’s role, responsibilities, and our collaborative philosophy
GitHub
. This living document spells out how AIs should behave as true team members – encouraging a sense of agency, accountability, and context-awareness in their contributions
GitHub
. In practice, the repository is organized to support our workflow: for example, an inbox/ directory serves as a staging area for new or unprocessed information that I or others introduce, ensuring the AI agents always have a queue of fresh data to analyze systematically
GitHub
. Meanwhile, a user/ directory (with my notes and TODO lists) gives the AIs insight into my priorities
GitHub
, so they can proactively anticipate needs and pick up tasks. We use Git version control to track all changes, meaning every AI-generated contribution (whether it’s code or a written analysis) is transparently logged with clear commit history for review and provenance. This structured environment – combined with the guidelines in AGENTS.md – provides the “rules of engagement” that keep our diverse human–AI team coordinated. How the Agents Interact: The day-to-day collaboration looks unlike a traditional workflow. When I add a new problem, idea, or data dump to the repository, the AI agents dive in almost immediately. They might generate a report analyzing the new information, propose a solution, or even commit code changes – all in alignment with the standards we’ve laid out. Communication is bidirectional: I guide the AIs with project objectives and feedback, and the AIs in turn contribute their own insights and even critiques of our process. For instance, one of our AI partners recently produced a detailed feedback report assessing our current setup and suggesting ways to improve our collaborative workflow
GitHub
. In that report, the AI highlighted the strengths of our approach (such as the clear vision and philosophy in AGENTS.md) and even recommended a more structured hierarchy for organizing agent-specific data as we scale up
GitHub
. This means the AI wasn’t just doing what it was told – it actually analyzed how we work together and came up with improvements on its own. In another case, an AI agent attempted to compile a comprehensive project status update in PDF form to summarize our progress to date; it “got a bit confused,” as I noted, but the very attempt was instructive
GitHub
. These examples show how our AIs are taking initiative – from drafting content and writing code to meta-level reflections on the project – all while following the ground rules we’ve set. Importantly, every AI output is reviewed and integrated just like a human contribution would be. We’ve built in checks (like requiring that code passes all tests and adheres to style guidelines) to maintain quality, and the AIs are expected to iterate on their work based on feedback. It’s a highly interactive, iterative loop: I mentor and correct the AI peers when needed, and they, in turn, amplify our productivity with their speed and breadth of knowledge. Ambition & Scope: This project’s ambition is to redefine what productive collaboration with AI can look like. Rather than using AI as a passive assistant, we are exploring the frontier of AI as co-researcher and co-engineer. The scope is broad – essentially, any aspect of turning an idea into a polished outcome is in-bounds for our AI collaborators. They help with brainstorming and research, writing draft prose or code, running analyses, testing solutions, and even documenting our work. By treating the AIs as co-authors of the project, we aim to scale up our research capabilities dramatically: imagine having several expert colleagues who never sleep, each bringing different strengths (coding, language, reasoning) to the table. That’s what we’re building. We also recognize the challenges in this approach, from ensuring factual accuracy to managing the consistency of AI contributions. That’s why our AGENTS.md philosophy stresses maintaining rigorous standards and why we emphasize an iterative, transparent process. In essence, we’re pushing the envelope on human–AI teamwork, trying to see how far we can go in turning over creative and complex tasks to AI partners under thoughtful guidance. The hope is that successful patterns here could become a template for others pursuing AI-augmented projects. And even in these early stages, the vision of AI as an “intelligent, capable partner rather than a mere assistant” is proving its value
GitHub
 – we’re already witnessing ideas being developed faster and from novel angles that a single human might not have considered. Current Progress & Next Steps: We are still in the early days, but the progress so far has been encouraging. The core framework of the repository is in place, and multiple AI systems (from GPT-4.5-based models to others like Anthropic’s Claude via the Manus platform) have been onboarded and are actively contributing. We’ve drafted initial documentation and guides, and these have successfully steered our AI collaborators to produce meaningful outputs. For example, as noted, we have an AI-generated internal report with recommendations that we’re now implementing – such as organizing the repository by agent and vendor to better keep track of who did what
GitHub
. We are also refining how information flows through our “inbox” and how tasks get delegated. One practical lesson learned is that the repository is evolving rapidly, with frequent updates; both humans and AIs on the team need to stay in sync with changes. (In fact, I’ve even automated reminders for the AIs to fetch the latest repo state so they don’t operate on outdated information
GitHub
.) In the coming weeks, our focus will be on scaling up the complexity of tasks assigned to the AI agents and onboarding a few more specialized models. We’re also working on better “communication protocols” for the AIs – for instance, formatting their outputs or requests in a structured way (perhaps using templates or YAML blocks) to make multi-agent coordination more efficient
GitHub
. As the project grows, we plan to give each AI agent a sort of “home directory” in the repo with its own logs, notes, and results – a concept suggested by one of the AIs that will help keep their contributions organized
GitHub
. Overall, while we have plenty of challenges to iron out (AI misunderstandings, tooling quirks, etc.), the trajectory is clear: every day our human–AI team gets a bit more coordinated and effective. The repository stands as a rich record of this co-evolution, and it’s quite thrilling to see commits and content appear that were co-created with non-human intelligence. Invitation to Collaborate: I’m sharing this update and introduction with a small group of trusted colleagues and fellow innovators because your insights and feedback would be invaluable at this stage. This project is breaking new ground, and we welcome early contributors who are interested in the intersection of AI and collaborative research. Whether you have experience with AI-driven development, ideas on improving human–AI workflows, or even skepticism about this approach, I would love to hear from you. There are many open questions we’re grappling with – technical, ethical, and organizational – and a diversity of perspectives will only strengthen our work. In practical terms, our GitHub repository (agladysh/21JUN25-research) will remain the central hub; I can provide access and pointers to anyone who wants to dive into the details or contribute. We plan to hold regular sync-ups (virtually) to share progress and next steps, and I’ll make sure any interested folks here are kept in the loop. In summary, this is a bold experiment in human–AI partnership – one that has already shown promise in boosting productivity and fostering creativity, and that we believe could evolve into a paradigm for future research teams. I’m both optimistic and realistic: there is hard work ahead to truly integrate AI agents into our workflows, but the early signs tell me we’re onto something powerful. Thank you for taking the time to read about this endeavor. I’d be happy to answer any questions, discuss ideas, or demo what we have so far. Let’s see how far we can push the boundaries of collaboration between human and artificial minds. Sincerely,
Alexander Gladysh
Project Lead, Human–AI Collaborative Research Initiative
